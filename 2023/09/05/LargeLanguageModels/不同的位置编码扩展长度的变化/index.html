<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		不同的位置编码扩展长度的变化 | 
	 
	Wangyaqi&#39;s personal site &lt;span style=&#34;color:wheat;font-size:x-small&#34;&gt;图片浏览须科学上网,公式渲染需要刷新&lt;/span&gt;
	</title>
	
	<!-- keywords,description -->
	 
		<meta name="description" content="about study notes" />
	

	<!-- favicon -->
	
	<link rel="shortcut icon" href="/favicon.ico">
	


	<!-- search -->
	<script>
		var searchEngine = "https://www.google.com/search?q=";
		if(typeof searchEngine == "undefined" || searchEngine == null || searchEngine == ""){
			searchEngine = "https://www.google.com/search?q=";
		}
		var homeHost = "wujun234.github.io";
		if(typeof homeHost == "undefined" || homeHost == null || homeHost == ""){
			homeHost = window.location.host;
		}
	</script>


	
<link rel="stylesheet" href="/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">


	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/js/main.js"></script>

	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@v1.4.14/dist/Valine.min.js"></script>

	
	
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	

	<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>
	<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3efe99c287df5a1d6f0d02d187e403c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<header id="header">
    <a id="title" href="/" class="logo">Wangyaqi's personal site <span style="color:wheat;font-size:x-small">图片浏览须科学上网,公式渲染需要刷新</span></a>

	<ul id="menu">
		<li class="menu-item">
			<a href="/about" class="menu-item-link">ABOUT</a>
		</li>
	
		<li class="menu-item">
			<a href="/tags" class="menu-item-link">标签</a>
		</li>
	

	
		<li class="menu-item">
			<a href="/categories" class="menu-item-link">分类</a>
		</li>
	

		<li class="menu-item">
			<a href="https://github.com/wujun234/uid-generator-spring-boot-starter" class="menu-item-link" target="_blank">
				UidGenerator
			</a>
		</li>
		<li class="menu-item">
			<a href="https://github.com/wujun234" class="menu-item-link" target="_blank">
				<i class="fa fa-github fa-2x"></i>
			</a>
		</li>
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="search" placeholder="按回车全站搜索">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										LargeLanguageModels
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/09/04/LargeLanguageModels/DPO/">
                     
										    DPO
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/LLaMA%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84/">
                     
										    LLaMA模型架构
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/LoRA/">
                     
										    LoRA
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/04/LargeLanguageModels/Toolformer/">
                     
										    Toolformer
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/alpaca_LoRA%E5%AE%9E%E7%8E%B0/">
                     
										    alpaca_LoRA实现
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/05/LargeLanguageModels/gpt_training/">
                     
										    gpt_training
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/05/LargeLanguageModels/llama2/">
                     
										    llama2
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/LargeLanguageModels/llama_bloom_chatglm%E5%8C%BA%E5%88%AB/">
                     
										    llama_bloom_chatglm区别
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/llama_visualization/">
                     
										    llama_visualization
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/peft_model/">
                     
										    peft_model
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/transformer/">
                     
										    transformer
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/LargeLanguageModels/xlnet/">
                     
										    xlnet
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/2023/09/05/LargeLanguageModels/%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E6%89%A9%E5%B1%95%E9%95%BF%E5%BA%A6%E7%9A%84%E5%8F%98%E5%8C%96/">
                     
										    不同的位置编码扩展长度的变化
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/04/LargeLanguageModels/%E7%A8%80%E7%96%8F%E5%8F%98%E6%8D%A2%E5%99%A8/">
                     
										    稀疏变换器
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/05/LargeLanguageModels/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96UIE/">
                     
										    通用信息抽取UIE
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/04/LargeLanguageModels/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%8F%98%E7%A7%8D%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%92%8C%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/">
                     
										    预训练模型变种的设计思路和建模方法
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										机器学习
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										kaggle_note
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/kaggle_note/text_classification/">
                     
										    text_classification
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										nlp
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/nlp/crf/">
                     
										    crf
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										paper
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/paper/asr%E8%AF%84%E4%BC%B0/">
                     
										    asr评估
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										深度学习
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GBRANK/">
                     
										    GBRANK
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/09/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/HNSW%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E7%9A%84%E5%8E%9F%E7%90%86/">
                     
										    HNSW向量检索的原理
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MMoE/">
                     
										    MMoE
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention/">
                     
										    attention
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-learning/">
                     
										    q-learning
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96%E5%99%A8/">
                     
										    优化器
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">
                     
										    常见网络的代码实现
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0ppo/">
                     
										    强化学习ppo
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0ppo%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/">
                     
										    强化学习ppo代码阅读
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">
                     
										    损失函数
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">
                     
										    激活函数
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/">
                     
										    知识蒸馏
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										项目集合
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E9%A1%B9%E7%9B%AE%E9%9B%86%E5%90%88/llama_%E5%B0%8F%E5%AD%A6%E6%95%B0%E5%AD%A6%E8%A7%A3%E9%A2%98%E6%A8%A1%E5%9E%8B/">
                     
										    llama_小学数学解题模型
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E9%A1%B9%E7%9B%AE%E9%9B%86%E5%90%88/stableDiffusion/">
                     
										    stableDiffusion
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content">
		<h1 id="article-title">
	不同的位置编码扩展长度的变化
</h1>
<div class="article-meta">
	
		<span>
			阅读量:<span id="/2023/09/05/LargeLanguageModels/%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E6%89%A9%E5%B1%95%E9%95%BF%E5%BA%A6%E7%9A%84%E5%8F%98%E5%8C%96/" class="leancloud_visitors" data-flag-title="不同的位置编码扩展长度的变化"></span>
		</span>
	
	<span>wang yaqi</span>
	<span>2023-09-05 23:19:21</span>
		<div id="article-categories">
    
		<span>Categories：</span>
            
    

    
		<span>Tags：</span>
            
    
		</div>

</div>

<div id="article-content">
	<p>在Meta和合作机构于21年发表的论文「TRAIN SHORT, TEST LONG」[2]中，作者展示了采用这一思路的评估结论。它比较了Sinusoidal，Rotary Position和T5 Bias三种位置embedding算法在固定长度训练，变长的序列输入做预测时，perplexity指标[3]变化的情况。perplexity也叫困惑度指标，用于评估LLM的生成能力。困惑度越低，模型生成的文本越符合语言的统计规律，越可能是人类写的文本。反之则越不符合人类习惯，越像胡说八道。</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171916023.png" />

</div>
<p>上面左图是当模型按照512 token长度序列训练后，测试512-16000个token长度的输入序列预测后的perplexity指标变化情况。右图和左图类似，只是模型是按照1024 token长度训练。可以明显看出，Sinusoidal，Rotary Position和T5 Bias三种算法的perplexity随着预测序列长度的增加而迅速上涨，说明此时大模型输出的文本已经不可用，完全无意义了。</p>
<h2 id="alibi">AliBi</h2>
<p>ALiBi方法ALiBi方法的思想是采用外延的方式。去掉position embedding叠加这一步骤，改为在query和key向量点乘之后，增加一个bias： <span class="math inline">\(softmax(q_iK^T+m \cdot [-(i-1),\dots,-2, -1, 0])\)</span>其中i为token的位置偏移量(<span class="math inline">\(1\le i \le L\)</span>)，m为每个head分配的倾斜常量，当head为n的时候，m为几何数列：<span class="math inline">\(\frac{1}{2^{\frac{8}{n}}}, \frac{1}{2^{\frac{16}{n}}},\dots, \frac{1}{2^8}\)</span> 。 通过增加这样一个bias，模型在训练时将学习到位置关系，起到了position embedding的效果。可视化效果如下： <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171919782.png" /> 其实就是在softmax之前减掉了一个非负矩阵，可以看做： <span class="math inline">\(q_ik_j-m \cdot |i-j|\)</span>类似减去这样一个矩阵： <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171920684.png" /> 从上图可以看出，本质上是将token之间的注意力权重，按照距离进行了线性降权，两个token之间的距离越远，降权越多。距离越近，降权越低。这样当预测时序列长度距离远超过训练训练长度时，整个注意力集中在局部区域内，相当于一种局部attention机制了。 ALiBi论文认为，这种方法相对经典的Sinusoidal方法延展性性更好，预测超过训练长度的上下文长度，也能给出较低的perplexity值，下图也给出了测试数据。 <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171920796.png" /> 实际上，BLOOM[7], MPT[8]，baichuan-13B模型[9]采用的就是ALiBi位置编码，据baichuan官方文档介绍，采用ALiBi位置编码后，计算量更小，对推理性能有显著提升；与标准的 LLaMA-13B 相比，平均推理速度 (tokens/s) 实测提升 31.6%（但没给出perplexity评估数据）。</p>
<h2 id="线性内插法">线性内插法</h2>
<p>线性内插法从2021年到2023年期间，业界也出现了很多类似做外推方法的扩展，典型的如Microsoft公司发表的XPOS方法[10]等。但这些方法一直通过外延的思路来解决问题，效果上并没有特别大的突破，尤其是如何在流行的RoPE位置编码算法的基础上进行扩展，并没有特别好的方法。直到2023年6月，由网友kaiokendev在他的博客上发表了一篇博文，只需在RoPE编码算法的基础之上增加2行代码，就能搞定上下文长度扩展问题。据作者说明，他花了1个月的时间研究各种文献，最终从AliBi作者的一次演讲中获得灵感，发现只需要2行代码就能搞定。这种方法最大可以将LLaMa这样的模型支持的上下文长度稳定地从2K扩展到8K，可谓神来之笔。 后来我们可以看出，这种方法是一种线性内插法。介绍这种方法需要对RoPE位置编码算法[11]有一些了解。RoPE是由苏剑林等人发明的一种旋转式位置编码算法，被用于LLaMa等一众开源LLM中。RoPE的基本原理很简单，给定一个位置序号<span class="math inline">\(m \in [1,c)\)</span>和一个嵌入向量 <span class="math inline">\(x:=[x_1,x_2,\dots,x_d]^T\)</span>，其中d为每个attention head的维度。RoPE算法定义如下矩阵变换： <span class="math inline">\(f_{q,k}(x_m,m) = R^d_{\Theta,m}W_{q,k}x_m\)</span>其中:Ï <span class="math inline">\(R^d_{\Theta,m} = \begin{pmatrix} cos(m\theta_1) &amp; -sin(m\theta_1) &amp; 0 &amp; 0 &amp; \dots &amp; 0 &amp; 0 \\ sin(m\theta_1) &amp; cos(m\theta_1) &amp; 0 &amp; 0 &amp; \dots &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; cos(m\theta_2) &amp; -sin(m\theta_2) &amp; \dots &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; sin(m\theta_2) &amp; cos(m\theta_2) &amp; \dots &amp; 0 &amp; 0 \\ \vdots &amp; \vdots &amp;\vdots &amp;\vdots &amp;\ddots &amp;\vdots &amp;\vdots &amp; \\ 0 &amp; 0&amp; 0 &amp; 0 &amp; \dots &amp; cos(m\theta_{d/2}) &amp; -sin(m\theta_{d/2}) \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \dots &amp; sin(m\theta_{d/2}) &amp; cos(m\theta_{d/2}) \\ \end{pmatrix}\)</span>其中<span class="math inline">\(\theta_i=10000^{-2(i-1)/d},i \in [1,2,\dots,d/2]\)</span>。 通过这个函数变换query和key向量，就能在这两个向量中叠加了位置信息。这种编码相对Transformer算法经典的Sinusoidal方法而言，采用了相对位置编码，不受绝对位置影响。可以证明两个token之间的attention score仅依赖于两个token之间的距离。实际应用中，将每一层attention算子的query和key向量进行RoPE函数变换即可。 RoPE作为国产原创算法，一经提出，被业界迅速采纳。PaLM，LLaMA，GLM-130B都通过这个位置编码获得稳定性能提升。这个算法的实现简洁，效率较高，兼容性强。 但RoPE用来外推更长序列的时候遇到了困难。实际测试发现，如果用2048个token来训练模型，但在超过2048个token的位置预测输出回答问题，那么回答的问题将是乱七八糟，完全不会考虑前面2048个token的上下文。更有甚者，如果我们在第3000个token的位置回答问题，模型将无法利用2900位置的上下文信息。也就是说，上下文关联性完全丧失。 为什么会发生这个现象，如下图可看出端倪，如果我们将超过训练上下文长度的attention score随着长度变化展示出来，可以发现一旦超过训练长度，attention score将远超过正常值(例如<span class="math inline">\(&amp;gt;10^3\)</span>倍)，完全不可用，输出无意义的序列也是可想而知的。 <img src="en-resource://database/3160:1" alt="ae68dadff429d50494acc5d698f0bcf2.png" /> 既然外推可不行，是否还有其他方法？网友kaiokendev[4]和Meta的田渊栋团队[5]几乎同时发现了线性内插法。内插法顾名思义，不再是预测出超过训练上下文长度的位置向量值，而是将现有的位置向量进行缩放，使之支持更长的长度，如下图所示： <img src="en-resource://database/3161:1" alt="f193fd7aeed91b0caeb21bd4b5161509.png" /> 而线性内插法的思想非常简单，就是将上面RoPE算法中的m替换成<span class="math inline">\(\dfrac{mL}{L&#39;}\)</span>即可，其中<span class="math inline">\(L\)</span>为训练最大长度，<span class="math inline">\(L&#39;\)</span>为预测最大长度。举个例子，如果训练长度是2048，预测时支持4096长度，只需要将位置序号<span class="math inline">\([1, 2, \dots, 2048,\dots, 4096]\)</span>替换成<span class="math inline">\([0.5, 1, 1.5, \dots, 2048]\)</span>即可。而kaiokendev修改的两行代码，其实就是将变量<span class="math inline">\(\theta_i\)</span>乘以一个scale变量即可。 但如果只是预测时变换了位置序号直接计算，效果并不好，这个方法还需要配合fine-tuning。fine-tuning过程需要按照期望的扩展上下文长度，用新的语料做Supervised Fine-tuning，按照缩放后的位置向量进行fine-tuning。按照论文[5]的介绍，只需要fine-tuning 1000步，即可获得理想的效果。在一些数据集中，上下文长度扩展到32K效果还保持不衰减。</p>
<h2 id="动态内插法">动态内插法</h2>
<p>那有没有什么更好的办法，不需要fine-tune就能直接在预测时扩充上下文长度呢？Reddit网友@bloc97在线性内插法提出一周后，就提出了新的NTK-Aware Scaled RoPE算法[6]。该算法无需fine-tune，轻松将2K上下文长度的LLama模型扩充到8K，而且perplexity值相对线性内插法更优，如下图所示： <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171940242.png" /> 动态内插法只是将RoPE公式中的<span class="math inline">\(\theta_i\)</span>的计算改造成<span class="math inline">\(\theta_i=(10000\alpha^{d/(d-2)})^{-2(i-1)/d}\)</span>，python实现也就三行代码。如此轻量级的改动就能实现无需fine-tuning还能扩充预测上下文长度，实在是令人惊奇。按照苏剑林的解释[12]，RoPE算法本质是数字n的<span class="math inline">\(\beta\)</span>进制编码，动态内插法本质上是一种进制转换，通过换成更高进制的数字表示，可以在缩放范围的同时，提供更高的精度，从而实现更好的位置embedding表示。 在NTK-Aware Scaled RoPE算法基础上，reddit网友@emozilla提出了Dynamically NTK-Aware Scaled RoPE算法[15]，实际上将算法中的<span class="math inline">\(\alpha\)</span>参数进一步动态缩放。按照他的评估结果，dynamic ntk算法效果最优，如下图所示： <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202308171941789.png" /> 上述所有的线性内插法和动态内插法，都已经在开源的transformers[13]，llama.cpp[14]等项目中落地应用了，感兴趣的同学可以参考具体实现的源代码。 在7月31日的苏剑林博客[16]中，作者按照<span class="math inline">\(\beta\)</span>进制编码理论，进一步推导出一种据称更优的位置编码算法NTK-RoPE-mixed，感兴趣可以进一步阅读了解下。 P.S. 最新发布的大模型都已经内置NTK等内插算法，普遍支持8K到16K的上下文长度，本文所讲的内容实际上都已经过时。</p>

</div>


    <div class="post-guide">
        <div class="item left">
            
              <a href="/2023/09/05/LargeLanguageModels/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96UIE/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  通用信息抽取UIE
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/2023/09/05/LargeLanguageModels/llama2/">
                llama2
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>



	<div id="vcomments"></div>


<script>
	
		// 评论
		new Valine({
			el: '#vcomments',
			appId: 'IGK6A3UjpP5uO7JWtA2JoBuS-gzGzoHsz',
			appKey: 'RRf6JtF145uakqoa7Hv1Ahr8',
			placeholder: '请输入评论',
			path: window.location.pathname,
			avatar: 'retro',
			highlight: false,
      recordIP: true,
      enableQQ: true,
			requiredFields: ['nick','mail']
		})
	
	
    // 显示次数
		function showTime(Counter) {
			var query = new AV.Query("Counter");
			if($(".leancloud_visitors").length > 0){
				var url = $(".leancloud_visitors").attr('id').trim();
				// where field
				query.equalTo("words", url);
				// count
				query.count().then(function (number) {
					// There are number instances of MyClass where words equals url.
					$(document.getElementById(url)).text(number?  number : '--');
				}, function (error) {
					// error is an instance of AVError.
				});
			}
		}
		// 追加pv
		function addCount(Counter) {
			var url = $(".leancloud_visitors").length > 0 ? $(".leancloud_visitors").attr('id').trim() : 'wujun234.github.io';
			var Counter = AV.Object.extend("Counter");
			var query = new Counter;
			query.save({
				words: url
			}).then(function (object) {
			})
		}
		$(function () {
			var Counter = AV.Object.extend("Counter");
			addCount(Counter);
			showTime(Counter);
		});
	
</script>
	</div>
	<div id="footer">
	<p>
	©2019-<span id="footerYear"></span> 
	<a href="/">wang yaqi</a>
	|<a href="https://beian.miit.gov.cn" target="_blank">京ICP备2022000211号-1</a>	
	
		|
		<span id="busuanzi_container_site_pv">
			pv
			<span id="busuanzi_value_site_pv"></span>
		</span>
		|
		<span id="busuanzi_container_site_uv"> 
			uv
			<span id="busuanzi_value_site_uv"></span>
		</span>
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//github.com/wujun234" target="_blank">WuJun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>
<script type="text/javascript"> 
	document.getElementById('footerYear').innerHTML = new Date().getFullYear() + '';
</script>
	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>
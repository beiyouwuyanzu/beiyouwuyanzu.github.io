<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		llama bloom chatglm对比 | 
	 
	Wangyaqi&#39;s personal site [notice:图片浏览须科学上网,公式渲染需要刷新]
	</title>
	
	<!-- keywords,description -->
	 
		<meta name="description" content="about study notes" />
	

	<!-- favicon -->
	
	<link rel="shortcut icon" href="/favicon.ico">
	


	<!-- search -->
	<script>
		var searchEngine = "https://www.google.com/search?q=";
		if(typeof searchEngine == "undefined" || searchEngine == null || searchEngine == ""){
			searchEngine = "https://www.google.com/search?q=";
		}
		var homeHost = "wujun234.github.io";
		if(typeof homeHost == "undefined" || homeHost == null || homeHost == ""){
			homeHost = window.location.host;
		}
	</script>


	
<link rel="stylesheet" href="/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">


	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/js/main.js"></script>

	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@v1.4.14/dist/Valine.min.js"></script>

	
	
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	

	<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>
	<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3efe99c287df5a1d6f0d02d187e403c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<header id="header">
    <a id="title" href="/" class="logo">Wangyaqi's personal site [notice:图片浏览须科学上网,公式渲染需要刷新]</a>

	<ul id="menu">
		<li class="menu-item">
			<a href="/about" class="menu-item-link">ABOUT</a>
		</li>
	
		<li class="menu-item">
			<a href="/tags" class="menu-item-link">标签</a>
		</li>
	

	
		<li class="menu-item">
			<a href="/categories" class="menu-item-link">分类</a>
		</li>
	

		<li class="menu-item">
			<a href="https://github.com/wujun234/uid-generator-spring-boot-starter" class="menu-item-link" target="_blank">
				UidGenerator
			</a>
		</li>
		<li class="menu-item">
			<a href="https://github.com/wujun234" class="menu-item-link" target="_blank">
				<i class="fa fa-github fa-2x"></i>
			</a>
		</li>
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="search" placeholder="按回车全站搜索">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										LargeLanguageModels
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/LLaMA%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84/">
                     
										    LLaMA模型架构
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/LoRA/">
                     
										    LoRA
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/alpaca_LoRA%E5%AE%9E%E7%8E%B0/">
                     
										    alpaca_LoRA实现
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/2023/07/08/LargeLanguageModels/llama_bloom_chatglm%E5%8C%BA%E5%88%AB/">
                     
										    llama_bloom_chatglm区别
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/llama_visualization/">
                     
										    llama_visualization
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/peft_model/">
                     
										    peft_model
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/LargeLanguageModels/transformer/">
                     
										    transformer
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/LargeLanguageModels/xlnet/">
                     
										    xlnet
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										机器学习
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										kaggle_note
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/kaggle_note/text_classification/">
                     
										    text_classification
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										nlp
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/nlp/crf/">
                     
										    crf
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										paper
									</a>
									
							<ul>
								<li class="file">
									<a href="/2021/12/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/paper/asr%E8%AF%84%E4%BC%B0/">
                     
										    asr评估
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										深度学习
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GBRANK/">
                     
										    GBRANK
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MMoE/">
                     
										    MMoE
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention/">
                     
										    attention
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-learning/">
                     
										    q-learning
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96%E5%99%A8/">
                     
										    优化器
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">
                     
										    常见网络的代码实现
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/07/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0ppo/">
                     
										    强化学习ppo
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">
                     
										    损失函数
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">
                     
										    激活函数
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/">
                     
										    知识蒸馏
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										项目集合
									</a>
									
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E9%A1%B9%E7%9B%AE%E9%9B%86%E5%90%88/llama_%E5%B0%8F%E5%AD%A6%E6%95%B0%E5%AD%A6%E8%A7%A3%E9%A2%98%E6%A8%A1%E5%9E%8B/">
                     
										    llama_小学数学解题模型
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/2023/05/08/%E9%A1%B9%E7%9B%AE%E9%9B%86%E5%90%88/stableDiffusion/">
                     
										    stableDiffusion
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content">
		<h1 id="article-title">
	llama bloom chatglm对比
</h1>
<div class="article-meta">
	
		<span>
			阅读量:<span id="/2023/07/08/LargeLanguageModels/llama_bloom_chatglm%E5%8C%BA%E5%88%AB/" class="leancloud_visitors" data-flag-title="llama bloom chatglm对比"></span>
		</span>
	
	<span>wang yaqi</span>
	<span>2023-07-08 21:04:50</span>
		<div id="article-categories">
    
		<span>Categories：</span>
            
    

    
		<span>Tags：</span>
            
    
		</div>

</div>

<div id="article-content">
	<h1 id="llama-bloom-chatglm对比">llama bloom chatglm对比</h1>
<div class="figure">
<img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307101650272.png" />

</div>
<h2 id="casual-decoder-vs-prefix-decoder">Casual Decoder vs Prefix Decoder</h2>
<p><img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307101655098.png" /> 蓝色：the attention between prefix tokens 绿色：the attention between prefix and target tokens 黄色：the attention betweetn target tokens and masked attention <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307101705035.png" /></p>
<h3 id="二者区别">二者区别</h3>
<p>以下是一些考虑因素： 1. <strong>实时性要求</strong>：如果需要实时处理和输出部分解码结果，Casual decoder可能更适合。它能够即时处理和输出部分解码结果，而不需要等待所有输入符号。这对于实时通信和流式数据处理很有用。 2. <strong>唯一解码要求</strong>：如果解码结果必须是唯一的，即给定一个输入序列只能有一种正确的解码方式，那么Prefix decoder是更合适的选择。前缀码的特性保证了唯一解码。 3. <strong>数据传输效率</strong>：在某些情况下，Casual decoder可能具有更高的数据传输效率。由于它可以即时处理和输出部分解码结果，可以更早地获取解码的信息，而不需要等待所有输入符号。 4. <strong>错误容忍性</strong>：如果输入符号中可能存在错误或丢失的情况，Prefix decoder可能更具容错性。由于它需要等待所有输入符号，可以在收到所有输入后进行完整的解码，并且能够检测到错误或丢失的符号。 综上所述，没有一个解码器可以被普遍视为更好，选择合适的解码器取决于具体的需求和约束条件。对于某些应用场景，Casual decoder可能更合适，而在其他情况下，Prefix decoder可能更适用。重要的是根据具体的需求和应用场景来评估和选择合适的解码器。</p>
<h2 id="rope位置编码">RoPE位置编码</h2>
<p>对于向量 q，使用 RoPE 添加位置编码后，用复数可以表示为：<span class="math inline">\(q e^{i m \theta}\)</span>，其中 <span class="math inline">\(\theta_i=10000^{-2i/d}​\)</span> 与经典的 Transformer 绝对位置编码相同。通过将向量以复数方式推理， RoPE 巧妙地实现了以添加绝对位置编码的方式，在 attention 中计算了相对位置信息。</p>
<p>RoPE 命名联系到了复数乘法的几何意义：对于复数 <span class="math inline">\(z=a+bi\)</span>，他可以表示为复平面上的向量。其中 x 轴为实部，y 轴为虚部。根据向量与 x 轴的夹角 <span class="math inline">\(ϕ\)</span>，我们可以将向量表示为 <span class="math inline">\(z=L(cosϕ+i * sinϕ)\)</span> ，其中 L 为向量模长。因此，向量的乘法变为了： <span class="math display">\[
z_1 z_2=L_1 L_2\left(\cos \left(\phi_1+\phi_2\right)+\sin \left(\phi_1+\phi_2\right)\right)
\]</span></p>
<p>所以，复数乘法也可以看作在复平面上的向量旋转及转换。</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307102042004.png" />

</div>
<h2 id="如何理解sinusoidal-position-embedding里面任意两个相同距离时间步之间的向量距离也相同">如何理解Sinusoidal Position Embedding里面任意两个相同距离时间步之间的向量距离也相同</h2>
<blockquote>
<p>https://www.qinglite.cn/doc/12476476a18a86265</p>
</blockquote>
<p>在Sinusoidal Position Embedding中，每个时间步的位置向量由两个正弦函数和余弦函数的组合构成。具体而言，对于每个时间步t和每个维度i，位置向量的计算公式如下：</p>
<p><span class="math inline">\(PE(t, i) = sin(t / 10000^{(2i/d_model)})\)</span>，当i为偶数 <span class="math inline">\(PE(t, i) = cos(t / 10000^{(2i/d_model)})\)</span>，当i为奇数</p>
<p>其中，t表示时间步，i表示维度，d_model表示位置向量的维度。</p>
<p>由于正弦函数和余弦函数的周期性特点，当时间步之间的距离相同时，位置向量中对应维度的数值是相同的。这意味着任意两个相同距离的时间步之间的向量距离也相同，因为它们在相同的维度上具有相同的数值。</p>
<h2 id="alibi-位置编码">ALiBi 位置编码</h2>
<p><img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307102108595.png" /> 直接走预设</p>
<h3 id="alibi和rope都是用于在transformer模型中引入位置信息的方法但rope在处理长序列时表现更好">ALiBi和RoPE都是用于在Transformer模型中引入位置信息的方法，但RoPE在处理长序列时表现更好</h3>
<h2 id="swiglu-激活函数">SwiGLU 激活函数</h2>
<h4 id="gated-linear-unit">Gated Linear Unit</h4>
<p>GLU激活函数的定义为：<span class="math inline">\(GLU(x) = x ⊗ σ(g(x))\)</span>。其中，x是输入向量，⊗表示逐元素相乘，σ表示Sigmoid函数，g(x)是通过全连接层或卷积层得到的中间向量。</p>
<p>GLU激活函数通过门控机制实现对输入的选择性过滤，帮助网络捕捉长期依赖关系和上下文信息。这种机制在处理序列数据和NLP任务中具有重要的作用，可以提高模型的性能和效果</p>
<pre><code>import torch
import torch.nn as nn

class GLU(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(GLU, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        gate = torch.sigmoid(self.linear(x))
        output = x * gate
        return output</code></pre>
<p>SwiGLU是一种激活函数，是GLU的一种变体。SwiGLU的定义如下：<span class="math inline">\(SwiGLU (x, W, V, b, c, β) = Swish β (x W + b) ⊗ (x V + c)\)</span>。<span class="math inline">\(Swish β (x) = x * sigmoid(βx)\)</span>，其中<span class="math inline">\(β\)</span>是指定常数</p>
<p>SwiGLU激活函数的优点是它结合了SWISH和GLU两者的特点 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qinduohao333/article/details/131085549">[url1]</a>。Swish激活函数具备无上界有下届、平滑、非单调的特性，Swish在深层模型上效果优于ReLU <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/630197707">[url2]</a>。GLU（Gated Linear Unit）激活函数是一种用于神经网络的激活函数，它具有门控机制，可以帮助网络更好地捕捉序列数据中的长期依赖关系<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/621058772">[3]</a>。</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307111540793.png" />

</div>
<p>非单调激活函数的好处是它可以避免梯度消失问题，从而提高模型的训练效率</p>
<h2 id="gelu">GeLU</h2>
<p><span class="math display">\[
\operatorname{GELU}(\mathrm{x})=0.5 \mathrm{x}\left(1+\tanh \left[\sqrt{2 / \pi}\left(\mathrm{x}+0.044715 \mathrm{x}^3\right)\right]\right)
\]</span> <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307111601795.png" /> GELU的优点是，它在处理负数时不会像ReLU一样将输入裁剪到0，这可能导致梯度消失的问题。</p>
<ul>
<li><p>具有更光滑的导数：</p></li>
<li><p>GELU函数的导数是连续的，这使得在训练深度神经网络时可以更容易地传播梯度，避免了ReLU函数在 处的导数不连续的问题，从而减少了训练过程中出现的梯度消失问题</p></li>
<li><p>可以加速收敛：</p></li>
<li><p>GELU函数在激活函数的非线性变换中引入了类似于sigmoid函数的变换，这使得GELU函数的输出可以落在一个更广的范围内，有助于加速模型的收敛速度。</p></li>
</ul>
<h3 id="swiglu和geglu的对比">SwiGLU和GeGLU的对比</h3>
<ol style="list-style-type: decimal">
<li>定义：
<ul>
<li>SwiGLU：SwiGLU的定义为Swish(xW + b) ⊗ (xV + c)，其中Swish是带有参数β的Swish激活函数。</li>
<li>GeGLU：GeGLU的定义为GELU(xW) ⊗ xV，其中GELU是高斯误差线性单元激活函数。</li>
</ul></li>
<li>激活函数比较：
<ul>
<li>SwiGLU：SwiGLU是GLU的变种，它使用Swish激活函数而不是ReLU或GELU。Swish是ReLU的平滑近似，对于负值具有非零梯度。由于其平滑性、非单调性和门控机制，SwiGLU在各种任务中表现优于其他激活函数，包括Swish和GLU。</li>
<li>GeGLU：GeGLU是GLU的另一种变种，它使用GELU激活函数。GELU是ReLU的平滑近似，在GPT-2和BERT等语言模型和Transformer模型中使用。它避免了梯度消失的问题，并且在0处具有连续的导数，有时可以加快训练速度。</li>
</ul></li>
</ol>
<h2 id="normal">normal</h2>
<h4 id="layer-normal">layer normal</h4>
<p><span class="math inline">\(\text{LayerNorm}(x_i) = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}\)</span></p>
<p>其中 <span class="math inline">\(x_i\)</span> 表示输入的第 <span class="math inline">\(i\)</span> 个特征，<span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma\)</span> 分别表示这个特征的均值和标准差，<span class="math inline">\(\epsilon\)</span> 是一个很小的数</p>
<p>Layer normalization 的计算是在每个样本的特征维度上进行的</p>
<p>通过标准化、缩放和平移操作，Layer normalization 可以使每个样本的特征在不同样本之间更加一致，有助于减少不同样本之间的差异，从而提高模型的泛化能力。此外，Layer normalization 还可以帮助解决神经网络中的梯度消失和梯度爆炸问题，促进模型的收敛和训练效果</p>
<h4 id="rms-normal">rms normal</h4>
<p>RMSNorm（Root Mean Square Layer Normalization）是一种深度学习中的归一化方法，它与 Layer Normalization 的主要区别在于去掉了减去均值的部分，计算公式为：<span class="math display">\[\text{RMSNorm}(a_i) = \frac{a_i}{\sqrt{\frac{1}{n}\sum_{i=1}^{n}a_i^2}}\]</span> 其中 <span class="math inline">\(a_i\)</span> 表示输入的第 <span class="math inline">\(i\)</span> 个特征，<span class="math inline">\(n\)</span> 表示特征的数量。</p>
<p>当应用RMS Normalization时，信号的均值并不影响信号的能量，<strong>因为均值只是信号的直流分量，而能量主要集中在信号的变化部分</strong>。因此，RMS Normalization仅使用信号的均方根值进行缩放，而不考虑均值。</p>
<p>而且节约时间和效率</p>
<h2 id="deep-norm">deep norm</h2>
<p>Deep Norm 是一种深度学习中的归一化方法，它是对 Layer Normalization 的改进，它在每个子层之间添加了一个归一化层，以便在不同的子层之间进行归一化。Deep Norm 的计算公式如下：</p>
<p><span class="math display">\[
x_{l+1}=L N\left(\alpha x+G_l\left(x_l, \theta_l\right)\right)
\]</span></p>
<p>其中， <span class="math inline">\(\alpha\)</span> 是一个常数（ <span class="math inline">\(\alpha\)</span>&gt;1 ）， <span class="math inline">\(G_l\left(x_l, \theta_l\right)\)</span>是参数为 <span class="math inline">\(\theta_l\)</span>的第 <span class="math inline">\(l\)</span>个Transformer子层（即注意力或前馈网络）的函数。DeepNet还将残差内部的权重<span class="math inline">\(\theta_l\)</span> 扩展了常数参数 <span class="math inline">\(\beta\)</span> 。</p>
<p>作者通过实验证实了Deep Norm在训练深层transformer模型的时候具备近乎恒定的更新规模，成功训练了1000层transformer的模型，认为Deep Norm在具备 _ **Post-LN 的良好性能_ 的同时又有 _Pre-LN 的稳定训练**_ <img src="https://raw.githubusercontent.com/dijiatrustlight/Chart_bed/master/img/202307112034774.png" /> 从上图可看出，相比于Post-LN结构梯度分布的不稳定，Pre-LN在各层之间梯度范数几乎保持不变，这种结构明显更利于优化器进行优化。而在进行一定轮数的 warm-up后，Post-LN的梯度范数也基本保持不变，并且其量级非常小(上图中绿色)，这也验证了Post-LN在warm-up阶段的训练不稳定性问题。 通过以上实验可发现，当使用Pre-LN结构时，warm-up阶段已不再是必需，并且Pre-LN结构可以大幅提升Transformer的收敛速度。对于机器翻译任务（IWSLT/WMT)，不需要warm-up的Pre-LN结构可以比Post-LN收敛快1倍左右，而在BERT上，Pre-LN在下游任务上达到和Post-LN相同的性能也只需要后者迭代轮数的1/3左右，并且最终的效果也更好。</p>

</div>


    <div class="post-guide">
        <div class="item left">
            
              <a href="/2023/07/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0ppo/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  强化学习ppo
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/2023/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-learning/">
                q-learning
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>



	<div id="vcomments"></div>


<script>
	
		// 评论
		new Valine({
			el: '#vcomments',
			appId: 'IGK6A3UjpP5uO7JWtA2JoBuS-gzGzoHsz',
			appKey: 'RRf6JtF145uakqoa7Hv1Ahr8',
			placeholder: '请输入评论',
			path: window.location.pathname,
			avatar: 'retro',
			highlight: false,
      recordIP: true,
      enableQQ: true,
			requiredFields: ['nick','mail']
		})
	
	
    // 显示次数
		function showTime(Counter) {
			var query = new AV.Query("Counter");
			if($(".leancloud_visitors").length > 0){
				var url = $(".leancloud_visitors").attr('id').trim();
				// where field
				query.equalTo("words", url);
				// count
				query.count().then(function (number) {
					// There are number instances of MyClass where words equals url.
					$(document.getElementById(url)).text(number?  number : '--');
				}, function (error) {
					// error is an instance of AVError.
				});
			}
		}
		// 追加pv
		function addCount(Counter) {
			var url = $(".leancloud_visitors").length > 0 ? $(".leancloud_visitors").attr('id').trim() : 'wujun234.github.io';
			var Counter = AV.Object.extend("Counter");
			var query = new Counter;
			query.save({
				words: url
			}).then(function (object) {
			})
		}
		$(function () {
			var Counter = AV.Object.extend("Counter");
			addCount(Counter);
			showTime(Counter);
		});
	
</script>
	</div>
	<div id="footer">
	<p>
	©2019-<span id="footerYear"></span> 
	<a href="/">wang yaqi</a>
	|<a href="https://beian.miit.gov.cn" target="_blank">京ICP备2022000211号-1</a>	
	
		|
		<span id="busuanzi_container_site_pv">
			pv
			<span id="busuanzi_value_site_pv"></span>
		</span>
		|
		<span id="busuanzi_container_site_uv"> 
			uv
			<span id="busuanzi_value_site_uv"></span>
		</span>
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//github.com/wujun234" target="_blank">WuJun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>
<script type="text/javascript"> 
	document.getElementById('footerYear').innerHTML = new Date().getFullYear() + '';
</script>
	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>